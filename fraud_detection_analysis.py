"""
TP - DÃ©tection de Fraude Xente - Version OptimisÃ©e
Analyse complÃ¨te de A Ã  Z
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    classification_report, 
    confusion_matrix, 
    roc_auc_score, 
    roc_curve,
    f1_score,
    accuracy_score
)
import warnings
warnings.filterwarnings('ignore')

# Configuration pour les graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("="*80)
print("TP - DÃ‰TECTION DE FRAUDE XENTE - ANALYSE COMPLÃˆTE")
print("="*80)

# ============================================================================
# Ã‰TAPE 1: CHARGEMENT DES DONNÃ‰ES
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 1: CHARGEMENT DES DONNÃ‰ES")
print("="*80)

# Chargement des donnÃ©es
train_df = pd.read_csv('xente-fraud-detection/training.csv')
test_df = pd.read_csv('xente-fraud-detection/test.csv')
variable_def = pd.read_csv('xente-fraud-detection/Xente_Variable_Definitions.csv')

print(f"\nDimensions du dataset d'entraÃ®nement: {train_df.shape}")
print(f"Dimensions du dataset de test: {test_df.shape}")

print("\n--- AperÃ§u des donnÃ©es d'entraÃ®nement ---")
print(train_df.head())

# ============================================================================
# Ã‰TAPE 2: ANALYSE EXPLORATOIRE DES DONNÃ‰ES (EDA)
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 2: ANALYSE EXPLORATOIRE DES DONNÃ‰ES (EDA)")
print("="*80)

# Statistiques descriptives
print("\n--- Statistiques descriptives ---")
print(train_df.describe())

# Distribution de la variable cible
print("\n--- Distribution de la variable cible (FraudResult) ---")
fraud_counts = train_df['FraudResult'].value_counts()
print(fraud_counts)
print(f"\nPourcentage de fraudes: {fraud_counts[1] / len(train_df) * 100:.2f}%")
print(f"Pourcentage de non-fraudes: {fraud_counts[0] / len(train_df) * 100:.2f}%")

# VÃ©rification des valeurs manquantes
print("\n--- Valeurs manquantes ---")
missing_values = train_df.isnull().sum()
print(missing_values[missing_values > 0])
if missing_values.sum() == 0:
    print("Aucune valeur manquante dÃ©tectÃ©e!")

# ============================================================================
# Ã‰TAPE 3: VISUALISATIONS
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 3: CRÃ‰ATION DES VISUALISATIONS")
print("="*80)

# CrÃ©ation d'un dossier pour les visualisations
import os
if not os.path.exists('visualizations'):
    os.makedirs('visualizations')

# 1. Distribution de la variable cible
plt.figure(figsize=(10, 6))
fraud_counts.plot(kind='bar', color=['green', 'red'])
plt.title('Distribution des Transactions (Fraude vs Non-Fraude)', fontsize=16, fontweight='bold')
plt.xlabel('FraudResult (0=Non-Fraude, 1=Fraude)', fontsize=12)
plt.ylabel('Nombre de transactions', fontsize=12)
plt.xticks(rotation=0)
for i, v in enumerate(fraud_counts):
    plt.text(i, v + 1000, str(v), ha='center', fontweight='bold')
plt.tight_layout()
plt.savefig('visualizations/1_distribution_fraude.png', dpi=300)
print("âœ“ Graphique 1 sauvegardÃ©: distribution_fraude.png")
plt.close()

# 2. Distribution des montants par type de transaction
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
train_df[train_df['FraudResult'] == 0]['Amount'].hist(bins=50, alpha=0.7, color='green', edgecolor='black')
plt.title('Distribution des montants - Non-Fraude', fontweight='bold')
plt.xlabel('Montant')
plt.ylabel('FrÃ©quence')

plt.subplot(1, 2, 2)
train_df[train_df['FraudResult'] == 1]['Amount'].hist(bins=50, alpha=0.7, color='red', edgecolor='black')
plt.title('Distribution des montants - Fraude', fontweight='bold')
plt.xlabel('Montant')
plt.ylabel('FrÃ©quence')
plt.tight_layout()
plt.savefig('visualizations/2_distribution_montants.png', dpi=300)
print("âœ“ Graphique 2 sauvegardÃ©: distribution_montants.png")
plt.close()

# 3. Fraude par catÃ©gorie de produit
plt.figure(figsize=(14, 6))
fraud_by_category = train_df.groupby('ProductCategory')['FraudResult'].agg(['sum', 'count'])
fraud_by_category['fraud_rate'] = (fraud_by_category['sum'] / fraud_by_category['count'] * 100)
fraud_by_category = fraud_by_category.sort_values('fraud_rate', ascending=False)
fraud_by_category['fraud_rate'].plot(kind='bar', color='coral')
plt.title('Taux de Fraude par CatÃ©gorie de Produit', fontsize=16, fontweight='bold')
plt.xlabel('CatÃ©gorie de Produit', fontsize=12)
plt.ylabel('Taux de Fraude (%)', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.savefig('visualizations/3_fraude_par_categorie.png', dpi=300)
print("âœ“ Graphique 3 sauvegardÃ©: fraude_par_categorie.png")
plt.close()

# 4. Fraude par canal (ChannelId)
plt.figure(figsize=(12, 6))
fraud_by_channel = train_df.groupby('ChannelId')['FraudResult'].agg(['sum', 'count'])
fraud_by_channel['fraud_rate'] = (fraud_by_channel['sum'] / fraud_by_channel['count'] * 100)
fraud_by_channel = fraud_by_channel.sort_values('fraud_rate', ascending=False)
fraud_by_channel['fraud_rate'].plot(kind='bar', color='skyblue')
plt.title('Taux de Fraude par Canal', fontsize=16, fontweight='bold')
plt.xlabel('Canal ID', fontsize=12)
plt.ylabel('Taux de Fraude (%)', fontsize=12)
plt.xticks(rotation=0)
plt.tight_layout()
plt.savefig('visualizations/4_fraude_par_canal.png', dpi=300)
print("âœ“ Graphique 4 sauvegardÃ©: fraude_par_canal.png")
plt.close()

# 5. Matrice de corrÃ©lation
plt.figure(figsize=(12, 10))
numeric_cols = train_df.select_dtypes(include=[np.number]).columns
correlation_matrix = train_df[numeric_cols].corr()
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)
plt.title('Matrice de CorrÃ©lation des Variables NumÃ©riques', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('visualizations/5_matrice_correlation.png', dpi=300)
print("âœ“ Graphique 5 sauvegardÃ©: matrice_correlation.png")
plt.close()

# ============================================================================
# Ã‰TAPE 4: FEATURE ENGINEERING
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 4: FEATURE ENGINEERING")
print("="*80)

def feature_engineering(df):
    """CrÃ©ation de nouvelles features"""
    df = df.copy()
    
    # Conversion de TransactionStartTime en datetime
    df['TransactionStartTime'] = pd.to_datetime(df['TransactionStartTime'])
    
    # Extraction de features temporelles
    df['Hour'] = df['TransactionStartTime'].dt.hour
    df['DayOfWeek'] = df['TransactionStartTime'].dt.dayofweek
    df['Month'] = df['TransactionStartTime'].dt.month
    df['IsWeekend'] = (df['DayOfWeek'] >= 5).astype(int)
    df['IsNightTime'] = ((df['Hour'] >= 22) | (df['Hour'] <= 6)).astype(int)
    
    # Ratio Amount/Value
    df['Amount_Value_Ratio'] = df['Amount'] / (df['Value'] + 1)
    
    # Log transformation
    df['Log_Amount'] = np.log1p(df['Amount'].abs())
    df['Log_Value'] = np.log1p(df['Value'])
    
    return df

# Application du feature engineering
train_df = feature_engineering(train_df)
test_df = feature_engineering(test_df)

print("âœ“ Features temporelles crÃ©Ã©es")
print("âœ“ Features de ratio crÃ©Ã©es")
print("âœ“ Features de transformation logarithmique crÃ©Ã©es")

# ============================================================================
# Ã‰TAPE 5: PRÃ‰PARATION DES DONNÃ‰ES POUR LE MODÃˆLE
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 5: PRÃ‰PARATION DES DONNÃ‰ES POUR LE MODÃˆLE")
print("="*80)

# SÃ©lection des features numÃ©riques uniquement pour simplifier
numeric_features = ['BatchId', 'AccountId', 'SubscriptionId', 'CustomerId', 
                   'ProviderId', 'ProductId', 'ChannelId', 'Amount', 'Value',
                   'PricingStrategy', 'Hour', 'DayOfWeek', 'Month', 'IsWeekend',
                   'IsNightTime', 'Amount_Value_Ratio', 'Log_Amount', 'Log_Value']

# VÃ©rifier que toutes les features existent
numeric_features = [f for f in numeric_features if f in train_df.columns]

print(f"\nNombre de features utilisÃ©es: {len(numeric_features)}")

# SÃ©paration des features et de la cible
X = train_df[numeric_features]
y = train_df['FraudResult']

# Division en ensembles d'entraÃ®nement et de validation
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nTaille de l'ensemble d'entraÃ®nement: {X_train.shape}")
print(f"Taille de l'ensemble de validation: {X_val.shape}")

# Normalisation des features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)

print("âœ“ Normalisation des features terminÃ©e")

# ============================================================================
# Ã‰TAPE 6: ENTRAÃŽNEMENT DES MODÃˆLES
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 6: ENTRAÃŽNEMENT DES MODÃˆLES")
print("="*80)

models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced'),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)
}

results = {}

for name, model in models.items():
    print(f"\n--- EntraÃ®nement: {name} ---")
    
    # EntraÃ®nement
    if name == 'Logistic Regression':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_val_scaled)
        y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_val)
        y_pred_proba = model.predict_proba(X_val)[:, 1]
    
    # Ã‰valuation
    accuracy = accuracy_score(y_val, y_pred)
    f1 = f1_score(y_val, y_pred)
    roc_auc = roc_auc_score(y_val, y_pred_proba)
    
    results[name] = {
        'model': model,
        'accuracy': accuracy,
        'f1_score': f1,
        'roc_auc': roc_auc,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }
    
    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1-Score: {f1:.4f}")
    print(f"ROC-AUC: {roc_auc:.4f}")

# ============================================================================
# Ã‰TAPE 7: COMPARAISON DES MODÃˆLES
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 7: COMPARAISON DES MODÃˆLES")
print("="*80)

# Tableau comparatif
comparison_df = pd.DataFrame({
    'ModÃ¨le': list(results.keys()),
    'Accuracy': [results[m]['accuracy'] for m in results.keys()],
    'F1-Score': [results[m]['f1_score'] for m in results.keys()],
    'ROC-AUC': [results[m]['roc_auc'] for m in results.keys()]
})

print("\n", comparison_df.to_string(index=False))

# Meilleur modÃ¨le
best_model_name = comparison_df.loc[comparison_df['ROC-AUC'].idxmax(), 'ModÃ¨le']
print(f"\nðŸ† Meilleur modÃ¨le: {best_model_name}")

# ============================================================================
# Ã‰TAPE 8: VISUALISATIONS DES PERFORMANCES
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 8: VISUALISATIONS DES PERFORMANCES")
print("="*80)

# 1. Comparaison des mÃ©triques
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
metrics = ['Accuracy', 'F1-Score', 'ROC-AUC']
colors = ['#3498db', '#e74c3c', '#2ecc71']

for idx, metric in enumerate(metrics):
    axes[idx].bar(comparison_df['ModÃ¨le'], comparison_df[metric], color=colors[idx], alpha=0.7)
    axes[idx].set_title(f'Comparaison - {metric}', fontweight='bold', fontsize=14)
    axes[idx].set_ylabel(metric, fontsize=12)
    axes[idx].set_xticklabels(comparison_df['ModÃ¨le'], rotation=45, ha='right')
    axes[idx].set_ylim([0, 1])
    
    for i, v in enumerate(comparison_df[metric]):
        axes[idx].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

plt.tight_layout()
plt.savefig('visualizations/6_comparaison_modeles.png', dpi=300)
print("âœ“ Graphique 6 sauvegardÃ©: comparaison_modeles.png")
plt.close()

# 2. Courbes ROC
plt.figure(figsize=(10, 8))
for name in results.keys():
    fpr, tpr, _ = roc_curve(y_val, results[name]['y_pred_proba'])
    plt.plot(fpr, tpr, label=f"{name} (AUC = {results[name]['roc_auc']:.3f})", linewidth=2)

plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier', linewidth=2)
plt.xlabel('Taux de Faux Positifs', fontsize=12)
plt.ylabel('Taux de Vrais Positifs', fontsize=12)
plt.title('Courbes ROC - Comparaison des ModÃ¨les', fontsize=16, fontweight='bold')
plt.legend(loc='lower right', fontsize=10)
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('visualizations/7_courbes_roc.png', dpi=300)
print("âœ“ Graphique 7 sauvegardÃ©: courbes_roc.png")
plt.close()

# 3. Matrices de confusion
fig, axes = plt.subplots(1, 3, figsize=(18, 5))
for idx, name in enumerate(results.keys()):
    cm = confusion_matrix(y_val, results[name]['y_pred'])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx], cbar=False)
    axes[idx].set_title(f'Matrice de Confusion - {name}', fontweight='bold', fontsize=12)
    axes[idx].set_xlabel('PrÃ©diction', fontsize=10)
    axes[idx].set_ylabel('RÃ©alitÃ©', fontsize=10)

plt.tight_layout()
plt.savefig('visualizations/8_matrices_confusion.png', dpi=300)
print("âœ“ Graphique 8 sauvegardÃ©: matrices_confusion.png")
plt.close()

# 4. Feature Importance (pour Random Forest)
if 'Random Forest' in results:
    rf_model = results['Random Forest']['model']
    feature_importance = pd.DataFrame({
        'feature': numeric_features,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False).head(15)
    
    plt.figure(figsize=(12, 8))
    plt.barh(range(len(feature_importance)), feature_importance['importance'], color='teal')
    plt.yticks(range(len(feature_importance)), feature_importance['feature'])
    plt.xlabel('Importance', fontsize=12)
    plt.title('Top 15 Features les Plus Importantes (Random Forest)', fontsize=16, fontweight='bold')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.savefig('visualizations/9_feature_importance.png', dpi=300)
    print("âœ“ Graphique 9 sauvegardÃ©: feature_importance.png")
    plt.close()

# ============================================================================
# Ã‰TAPE 9: PRÃ‰DICTIONS SUR LE TEST SET
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 9: PRÃ‰DICTIONS SUR LE TEST SET")
print("="*80)

# Utilisation du meilleur modÃ¨le
best_model = results[best_model_name]['model']

# PrÃ©paration des donnÃ©es de test
X_test = test_df[numeric_features]

# PrÃ©dictions
if best_model_name == 'Logistic Regression':
    X_test_scaled = scaler.transform(X_test)
    test_predictions = best_model.predict_proba(X_test_scaled)[:, 1]
else:
    test_predictions = best_model.predict_proba(X_test)[:, 1]

# CrÃ©ation du fichier de soumission
submission = pd.DataFrame({
    'TransactionId': test_df['TransactionId'],
    'FraudResult': test_predictions
})

submission.to_csv('submission.csv', index=False)
print(f"âœ“ Fichier de soumission crÃ©Ã©: submission.csv")
print(f"  Nombre de prÃ©dictions: {len(submission)}")
print(f"\nAperÃ§u des prÃ©dictions:")
print(submission.head(10))

# ============================================================================
# Ã‰TAPE 10: RAPPORT FINAL
# ============================================================================
print("\n" + "="*80)
print("Ã‰TAPE 10: RAPPORT FINAL")
print("="*80)

report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    RAPPORT FINAL - DÃ‰TECTION DE FRAUDE XENTE                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ðŸ“Š STATISTIQUES DU DATASET
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â€¢ Nombre total de transactions (train): {len(train_df):,}
  â€¢ Nombre total de transactions (test): {len(test_df):,}
  â€¢ Nombre de features utilisÃ©es: {len(numeric_features)}
  â€¢ Taux de fraude dans le dataset: {fraud_counts[1] / len(train_df) * 100:.2f}%

ðŸ”§ FEATURE ENGINEERING
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â€¢ Features temporelles: Hour, DayOfWeek, Month, IsWeekend, IsNightTime
  â€¢ Features de ratio: Amount_Value_Ratio
  â€¢ Features de transformation: Log_Amount, Log_Value

ðŸ¤– MODÃˆLES TESTÃ‰S
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

for name in results.keys():
    report += f"""
  {name}:
    - Accuracy:  {results[name]['accuracy']:.4f}
    - F1-Score:  {results[name]['f1_score']:.4f}
    - ROC-AUC:   {results[name]['roc_auc']:.4f}
"""

report += f"""
ðŸ† MEILLEUR MODÃˆLE
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  ModÃ¨le sÃ©lectionnÃ©: {best_model_name}
  ROC-AUC Score: {results[best_model_name]['roc_auc']:.4f}

ðŸ“ FICHIERS GÃ‰NÃ‰RÃ‰S
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  â€¢ submission.csv - PrÃ©dictions pour le test set
  â€¢ visualizations/ - Dossier contenant 9 graphiques d'analyse
    âœ“ 1_distribution_fraude.png
    âœ“ 2_distribution_montants.png
    âœ“ 3_fraude_par_categorie.png
    âœ“ 4_fraude_par_canal.png
    âœ“ 5_matrice_correlation.png
    âœ“ 6_comparaison_modeles.png
    âœ“ 7_courbes_roc.png
    âœ“ 8_matrices_confusion.png
    âœ“ 9_feature_importance.png

âœ… ANALYSE TERMINÃ‰E AVEC SUCCÃˆS!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
"""

print(report)

# Sauvegarde du rapport
with open('rapport_final.txt', 'w', encoding='utf-8') as f:
    f.write(report)

print("\nâœ“ Rapport final sauvegardÃ©: rapport_final.txt")
print("\n" + "="*80)
print("ðŸŽ‰ TP TERMINÃ‰! Tous les fichiers ont Ã©tÃ© gÃ©nÃ©rÃ©s avec succÃ¨s.")
print("="*80)
